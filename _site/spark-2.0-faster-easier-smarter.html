<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8" />
  <title>『 Spark 』12. Spark 2.0  | 10 个特性介绍 | 云在青天水在瓶</title>
  <meta name="baidu-site-verification" content="6b2f48c1baf35f9e0eb29b4455265203"/>
  <meta name="baidu-site-verification" content="hgXDOPtWLn" />
  <meta name="google-site-verification" content="YqjJD80rZQfugWoznvslaHlII_viwiMiUDEEgPTLEDw" />
  <meta name="renderer" content="webkit">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, minimum-scale=1.0">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="mobile-web-app-capable" content="yes">
  <link rel="stylesheet" href="/css/font-awesome/css/font-awesome.min.css" type="text/css" />
  <script src="/files/dc3da690b0d2a5655a8d6150862a2a07.html"></script>
  <!-- <link rel="stylesheet" href="/css/pygments.css" type="text/css" /> -->
  <link rel="stylesheet" href="/css/default-min.css" type="text/css" />
  <link rel="stylesheet" href="/css/desktop-min.css" type="text/css" />
  <link rel="stylesheet" href="/css/mobile-min.css" type="text/css" />
  <link rel="shortcut icon" href="/css/favicon.ico" type="image/x-icon" />
  <link rel="icon" href="/css/favicon.ico" mce_href="/favicon.ico" type="image/x-icon">
  <link rel="alternate" type="application/atom+xml" title="Recent Entries" href="/atom.xml" />
  <script src="/js/jquery-1.11.0.min.js" type="text/javascript"></script>
  <script src="/js/jquery-migrate-1.2.1.min.js" type="text/javascript"></script>
  <script src="/js/jquery.transit.min.js" type="text/javascript"></script>
  <script src="/js/common.js" type="text/javascript"></script>
  <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>

  
  <!-- growingIO code -->
  <script type='text/javascript'>
      var _vds = _vds || [];
      window._vds = _vds;
      (function(){
        _vds.push(['setAccountId', '9f3f34627219ccd1']);
        (function() {
          var vds = document.createElement('script');
          vds.type='text/javascript';
          vds.async = true;
          vds.src = ('https:' == document.location.protocol ? 'https://' : 'http://') + 'dn-growing.qbox.me/vds.js';
          var s = document.getElementsByTagName('script')[0];
          s.parentNode.insertBefore(vds, s);
        })();
      })();
  </script>
  
  <!-- 删掉 baidu spider 主动推送，无效 -->
  <!-- baidu spider initiative push -->
<!-- <script>
    (function(){
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';        
        }
        else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
  </script> -->
  
  <!-- google analytics push code -->
  <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-72176628-2', 'auto');
      ga('send', 'pageview');
  </script>

</head>

<!-- meiqia plug-in -->
<!-- 
<script type='text/javascript'>
    (function(m, ei, q, i, a, j, s) {
        m[a] = m[a] || function() {
            (m[a].a = m[a].a || []).push(arguments)
        };
        j = ei.createElement(q),
            s = ei.getElementsByTagName(q)[0];
        j.async = true;
        j.charset = 'UTF-8';
        j.src = i + '?v=' + new Date().getUTCDate();
        s.parentNode.insertBefore(j, s);
    })(window, document, 'script', '//static.meiqia.com/dist/meiqia.js', '_MEIQIA');
    _MEIQIA('entId', 15857);
</script>
 -->

<body>
  <link rel="stylesheet" href="/js/prettify/prettify.css" />
<style type="text/css">
  html {
    /*background: #333333;*/
    background: rgb(246, 246, 246);
    -webkit-background-size: cover;
    -moz-background-size: cover;
    -o-background-size: cover;
    background-size: cover;
  }
  /*body { background:transparent;}*/
  @media screen and (max-width: 770px){
    body { background: rgba(255, 255, 255, 0.9); }
  }
</style>

<div id="content" class="post" style="margin-top: 20px;">
  <div id="avatar" class="avatar circle" data-in-right="false" style="width: 150px; height: 150px; position: fixed; top: 40px; z-index: 99; opacity: 0;">
    <div class="center" style="margin-top: 4px; height: 142px; width: 142px; border-radius: 71px; background-image: url('../images/2.jpg');"></div>
  </div>

  <div class="entry" style="position: relative;">
    <h1 class="entry-title"><a href="/spark-2.0-faster-easier-smarter" title="『 Spark 』12. Spark 2.0  | 10 个特性介绍">『 Spark 』12. Spark 2.0  | 10 个特性介绍</a></h1>    

    <p class="entry-date">2016-06-16 
        <span class="lastModified" style="display: none;" data-source="_posts/new-spark/2016-06-16-spark-2.0-faster-easier-smarter.md">最后更新时间: 
        </span>
    </p>


    <h2 id="写在前面">写在前面</h2>

<p>本系列是综合了自己在学习spark过程中的理解记录 ＋ 对参考文章中的一些理解 ＋ 个人实践spark过程中的一些心得而来。写这样一个系列仅仅是为了梳理个人学习spark的笔记记录，所以一切以能够理解为主，没有必要的细节就不会记录了，而且文中有时候会出现英文原版文档，只要不影响理解，都不翻译了。若想深入了解，最好阅读参考文章和官方文档。</p>

<p>其次，本系列是基于目前最新的 spark 1.6.0 系列开始的，spark 目前的更新速度很快，记录一下版本号还是必要的。 <br />
最后，如果各位觉得内容有误，欢迎留言备注，所有留言 24 小时内必定回复，非常感谢。</p>

<p>Tips: 如果插图看起来不明显，可以：1. 放大网页；2. 新标签中打开图片，查看原图哦；3. 点击右边目录上方的 <em>present mode</em> 哦。</p>

<h2 id="1-spark-20-">1. Spark 2.0 !</h2>

<p>还记得我们的<a href="../spark-dataframe-introduction">第七篇 Spark 博文</a>里吗？里面我用三点来总结 spark dataframe 的好处：</p>

<p><img src="../images/spark-2.0-1.png" alt="spark-2.0-1.png" /></p>

<p>当时是主要介绍 spark 里的 dataframe，今天是想总结一下 spark 2.0 的一些重大更新，准备过段时间［等到 2.0.1 或者 2.1 出来了就］切换到 spark 2.x 来。当我看官方的一些介绍和一些相关文章的时候，我发现 spark 2.0 的特点，也可以用第七篇里总结的 dataframe 的特点来说明，那就是：</p>

<ul>
  <li><em>write less : 写更少的代码</em></li>
  <li><em>do more : 做更多的事情</em></li>
  <li><em>faster : 以更快的速度</em></li>
</ul>

<p>真心觉得 spark 做得很不错，databricks 做得太赞了，现在 databricks 的社区版 [DCE : Databricks Community Edition] 也开放注册了，大家还没有注册的赶紧去体验这个产品吧，so amazing，注册链接：<a href="community.cloud.databricks.com">community.cloud.databricks.com</a>。</p>

<p>言归正传，下面从几个亮点来总结一下 spark 2.0 的更新，基本上都是看官方文档，相关的 video，slide 和一些技术博文来的，参考的文章都会在后文列出来的。</p>

<h2 id="2-spark-版本号说明">2. Spark 版本号说明</h2>

<p>如图是 spark 版本号的三个不同数字的介绍，以 <em>1.6.0</em> 版本举例：</p>

<ul>
  <li><em>1 : major version</em> : 代表大版本更新，一般都会有一些 api 的变化，以及大的优化或是一些结构的改变；</li>
  <li><em>6 : minor version</em> : 代表小版本更新，一般会新加 api，或者是对当前的 api 就行优化，或者是其他内容的更新，比如说 WEB UI 的更新等等；</li>
  <li><em>0 : patch version</em> : 代表修复当前小版本存在的一些 bug，基本不会有任何 api 的改变和功能更新；记得有一个大神曾经说过，如果要切换 spark 版本的话，最好选 <em>patch version</em> 非 0 的版本，因为一般类似于 <em>1.2.0, … 1.6.0</em> 这样的版本是属于大更新的，有可能会有一些隐藏的 bug 或是不稳定性存在，所以最好选择 <em>1.2.1, … 1.6.1</em> 这样的版本。</li>
</ul>

<p><img src="../images/spark-2.0-2.png" alt="spark-2.0-2.png" /></p>

<h2 id="3-特性-1---官方文档">3. 特性 1 - 官方文档</h2>

<p>spark 2.0 似乎对官方文档做了比较大的改变，赞，这里是 2.0 预览版的文档链接，等不及的小伙伴们可以先看了：</p>

<ul>
  <li><a href="http://spark.apache.org/docs/2.0.0-preview/">2.0.0-preview</a></li>
  <li><a href="http://people.apache.org/~pwendell/spark-nightly/spark-master-docs/latest/index.html">master-docs </a></li>
  <li><a href="https://home.apache.org/~pwendell/spark-nightly/spark-branch-2.0-docs/latest/">2.0.0 docs</a></li>
</ul>

<h2 id="4-特性-2---支持标准-sql-语句">4. 特性 2 - 支持标准 SQL 语句</h2>

<blockquote>
  <blockquote>

    <p>On the SQL side, we have significantly expanded the SQL capabilities of Spark, with the introduction of a new ANSI SQL parser and support for subqueries. Spark 2.0 can run all the 99 TPC-DS queries, which require many of the SQL:2003 features.</p>
  </blockquote>
</blockquote>

<p>上面提到的 <em>TPC-DS</em> 这个概念没有必要去了解了，我是 google 了之后才知道的，如果感兴趣的话可以看这个链接：<a href="https://developer.ibm.com/hadoop/2015/11/30/99-tpc-ds-queries-integrated-into-spark-sql-perf/">TPC-DS</a>。</p>

<p>总结下来：</p>

<ul>
  <li>Spark 2.0 中, SQL:2003 语法全部支持了，下面是 sql 语法的发展历程，可以说，虽然 sql 2003 之后又更新了两个版本的语法，但在实际使用情况中，sql 2003 已经完全能 handle 99% 的场景了。</li>
</ul>

<blockquote>
  <blockquote>

    <p>1986年，ANSI X3.135-1986，ISO/IEC 9075:1986，SQL-86    <br />
1989年，ANSI X3.135-1989，ISO/IEC 9075:1989，SQL-89     <br />
1992年，ANSI X3.135-1992，ISO/IEC 9075:1992，SQL-92（SQL2）    <br />
1999年，ISO/IEC 9075:1999，SQL:1999（SQL3）   <br />
2003年，ISO/IEC 9075:2003，SQL:2003  <br />
2008年，ISO/IEC 9075:2008，SQL:2008  <br />
2011年，ISO/IEC 9075:2011，SQL:2011</p>
  </blockquote>
</blockquote>

<ul>
  <li>Spark 2.0 中，更新了新的 SQL 解析器，可以支持子查询了，特地重复一下，因为基本上所有复杂的 sql 语句都会用到子查询，官方有例子: <a href="https://databricks-prod-cloudfront.cloud.databricks.com/public/4027ec902e239c93eaaa8714f173bcfc/2728434780191932/1483312212640900/6987336228780374/latest.html">Subqueries in Apache Spark 2.0</a></li>
</ul>

<h2 id="5-特性-3---统一-dataframes-and-datasets-api">5. 特性 3 - 统一 DataFrames and Datasets API</h2>

<p>在 spark 2.0 中，把 dataframes 当作是一种特殊的 datasets，<strong><em>dataframes = datasets[row]</em></strong>，把两者统一为 datasets。但是需要注意的是，目前只更新了 scala 和 java 的api，python中尚未更新。而且 spark 2.0 中引入了 structured streaming 的概念，需要 dataframe 的支持，其中的 dataframe 也已经用 datasets[row] 来实现了。</p>

<p>官方的关于 DataSets API 的使用说明：<a href="https://databricks-prod-cloudfront.cloud.databricks.com/public/4027ec902e239c93eaaa8714f173bcfc/6122906529858466/431554386690871/4814681571895601/latest.html">Dataset API</a></p>

<h2 id="6-特性-4---sparksession">6. 特性 4 - SparkSession</h2>

<p>在 spark 2.0 之前，sparkContext 是 Spark应用的入口。除了 sparkContext，还有 sqlContext，StreamingContext，HiveContext 等其他入口。然而到了 spark 2.0 后，因为逐渐要采用 DataFrame 和 DataSets 作为 API 使用，需要一个统一的入口点，所以就诞生了 SparkSession。本质上，可以简单的把 SparkSession 理解成 sparkContext, sqlContext, StreamingContext, HiveContext 的统一封装。</p>

<p>下面是一个来自官方的 demo：</p>

<figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">import</span> <span class="nn">org.apache.spark.sql.SparkSession</span>
<span class="k">val</span> <span class="n">sparkSession</span> <span class="k">=</span> <span class="nc">SparkSession</span><span class="o">.</span><span class="n">builder</span>
  <span class="o">.</span><span class="n">master</span><span class="o">(</span><span class="s">"local"</span><span class="o">)</span>
  <span class="o">.</span><span class="n">appName</span><span class="o">(</span><span class="s">"my-spark-app"</span><span class="o">)</span>
  <span class="o">.</span><span class="n">config</span><span class="o">(</span><span class="s">"spark.some.config.option"</span><span class="o">,</span> <span class="s">"config-value"</span><span class="o">)</span>
  <span class="o">.</span><span class="n">getOrCreate</span><span class="o">()</span></code></pre></figure>

<p>值得注意的一个点是，在 2.0 之前，启动 spark repl 时，会自动给你创建一个 sparkContext，叫做 <em>sc</em>，但在 2.0 之后，启动 spark repl 时会自动给你创建一个 SparkSession，叫做 <em>spark</em>。</p>

<p><img src="../images/spark-2.0-3.png" alt="spark-2.0-3.png" /></p>

<p>这里有一个 databricks 出的关于 SparkSession 的说明文档和使用方法：<a href="https://databricks-prod-cloudfront.cloud.databricks.com/public/4027ec902e239c93eaaa8714f173bcfc/6122906529858466/431554386690884/4814681571895601/latest.html">SparkSession - a new entry point</a></p>

<h2 id="7-特性-5---新的-accumulator-api">7. 特性 5 - 新的 Accumulator API</h2>

<p>spark 2.0 设计了新的 Accumulator API，用户可以基于默认的 Accumulator 实现自己定义的 Accumulator，当然老的 Accumulator 还是保留使用的。</p>

<p>下面是一个用户自定义 Accumulator 的例子：</p>

<figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">class</span> <span class="nc">VectorAccumulatorParam</span><span class="o">(</span><span class="nc">AccumulatorParam</span><span class="o">)</span><span class="k">:</span>
    <span class="kt">def</span> <span class="kt">zero</span><span class="o">(</span><span class="kt">self</span><span class="o">,</span> <span class="kt">initialValue</span><span class="o">)</span><span class="k">:</span>
        <span class="kt">return</span> <span class="kt">Vector.zeros</span><span class="o">(</span><span class="kt">initialValue.size</span><span class="o">)</span>

    <span class="kt">def</span> <span class="kt">addInPlace</span><span class="o">(</span><span class="kt">self</span><span class="o">,</span> <span class="kt">v1</span><span class="o">,</span> <span class="n">v2</span><span class="o">)</span><span class="k">:</span>
        <span class="kt">v1</span> <span class="kt">+=</span> <span class="kt">v2</span>
        <span class="k">return</span> <span class="n">v1</span>

<span class="k">#</span> <span class="nc">Then</span><span class="o">,</span> <span class="n">create</span> <span class="n">an</span> <span class="nc">Accumulator</span> <span class="n">of</span> <span class="k">this</span> <span class="n">type</span><span class="k">:</span>
<span class="kt">vecAccum</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">accumulator</span><span class="o">(</span><span class="nc">Vector</span><span class="o">(...),</span> <span class="nc">VectorAccumulatorParam</span><span class="o">())</span></code></pre></figure>

<p>而且 spark 2.0 里可以在 web ui 里查看 Accumulator 的数据了，非常方便［注明一下，这里我没有尝试过在 2.0 之前是否可以在 web ui 里查看 Accumulator 的数据，如果有写错了请大家指出哈，谢谢］</p>

<p><img src="../images/spark-2.0-4.png" alt="spark-2.0-4.png" /></p>

<h2 id="8-特性-6---dataframe-based-machine-learning">8. 特性 6 - DataFrame Based Machine Learning</h2>

<p>在上篇文章里 <a href="../spark-mlib-machine-learning">『 Spark 』11. spark 机器学习</a>，我们也提到过，从 2.0 开始，spark machine learning 开始采用基于 dataframe 开发的 ml package，基于 RDD API 的 mllib 将不再开发新 feature，只做维护。</p>

<h2 id="9-特性-7---machine-learning-pipeline-persistence">9. 特性 7 - Machine learning pipeline persistence</h2>

<p>spark 2.0 支持机器学习持久化了，虽然 2.0 之前也有类似的功能，但在这方面，2.0 有两大亮点：</p>

<ul>
  <li>不仅可以 save &amp; load 模型，还可以 save &amp; load 模型的 pipeline；</li>
  <li>可以跨语言 save &amp; load 模型，比如说你用 scala 实现了一个模型，并且 save 到磁盘上，之后可以用 python 来 load 这个模型；</li>
</ul>

<p>这里有官方出的一个介绍文档和使用说明：<a href="https://databricks-prod-cloudfront.cloud.databricks.com/public/4027ec902e239c93eaaa8714f173bcfc/6122906529858466/100429797847215/4814681571895601/latest.html">Saving &amp; loading Machine Learning (ML) models</a></p>

<h2 id="10-特性-8---distributed-algorithms-in-r">10. 特性 8 - Distributed algorithms in R</h2>

<p>也可以用 R 来实现一些机器学习算法了： Generalized Linear Models (GLM), Naive Bayes, Survival Regression, and K-Means.</p>

<h2 id="11-特性-9---whole-stage-code-generation">11. 特性 9 - Whole-stage code generation</h2>

<p>spark 2.0 性能上会有较大的提升，根据官方文档，2.0 会引入新的物理执行引擎 <em>new Tungsten execution engine</em>，相对于之前的执行引擎［之前也有 code generation］，新的物理执行引擎会充分利用 <em>内存，cpu，cpu 寄存器</em> 三者，最大化的提升代码执行速度。</p>

<p>关于 <em>new Tungsten execution engine</em> 的原理，可以参考这篇官方博客：<a href="https://databricks.com/blog/2016/05/23/apache-spark-as-a-compiler-joining-a-billion-rows-per-second-on-a-laptop.html">Apache Spark as a Compiler: Joining a Billion Rows per Second on a Laptop : Deep dive into the new Tungsten execution engine</a></p>

<p>这里有官方做的一个简单的测试：<a href="https://databricks-prod-cloudfront.cloud.databricks.com/public/4027ec902e239c93eaaa8714f173bcfc/6122906529858466/293651311471490/5382278320999420/latest.html">Performance of Spark 2.0’s Tungsten engine</a></p>

<p>下图是一个简要的性能对比截图：
<img src="../images/spark-2.0-5.png" alt="spark-2.0-5.png" /></p>

<h2 id="12-特性-10---structured-streaming">12. 特性 10 - Structured Streaming</h2>

<p>这个就不用说了，是 2.0 的三大更新之一。官方的这句话很有意思: <em>the simplest way to compute answers on streams of data is to not having to reason about the fact that it is a stream.</em>，中文翻译来说就是说：<em>处理流式计算最简单的方法，就是不要特地去区分流式计算与非流式计算的区别［因为归根结底，他们都是数据，我们要区分的，并不是数据本身，而是我们处理数据的方式］</em></p>

<p>在 rxin 的这个 slide 里，<a href="http://www.slideshare.net/databricks/apache-spark-20-faster-easier-and-smarter">Apache Spark 2.0: Faster, Easier, and Smarter</a>，第 17 ～ 26 也专门有说 2.0 里的 structure streaming，非常值得借鉴。</p>

<p>下面是其中两张需要理解的 ppt 截图：</p>

<p><img src="../images/spark-2.0-6.png" alt="spark-2.0-6.png" />
<img src="../images/spark-2.0-7.png" alt="spark-2.0-7.png" /></p>

<h2 id="13-next">13. Next</h2>

<p>最近 databricks 出了一篇非常不错的文章，讲 spark 的一些概念的，个人觉得非常不错，下一篇就翻译这篇文章吧。届时大家可以结合起第二篇文章一起理解：<a href="http://litaotao.github.io/spark-questions-concepts?s=inner">『 Spark 』2. spark 基本概念解析 </a></p>

<h2 id="14-打开微信扫一扫点一点棒棒的_">14. 打开微信，扫一扫，点一点，棒棒的，^_^</h2>

<p><img src="../images/wechat_pay_6-6.png" alt="wechat_pay_6-6.png" /></p>

<h2 id="参考文章">参考文章</h2>

<ul>
  <li><a href="https://www.youtube.com/watch?v=ZFBgY0PwUeY&amp;feature=youtu.be">Spark 2 0</a></li>
  <li><a href="http://www.slideshare.net/databricks/apache-spark-20-faster-easier-and-smarter"><code class="highlighter-rouge">slide</code> Spark 2 0</a></li>
  <li><a href="http://www.slideshare.net/databricks/apache-spark-20-faster-easier-and-smarter">Apache Spark 2.0: Faster, Easier, and Smarter</a></li>
  <li><a href="https://databricks.com/blog/2016/05/11/spark-2-0-technical-preview-easier-faster-and-smarter.html">Preview of Apache Spark 2.0 now on Databricks Community Edition</a></li>
  <li><a href="https://databricks.com/blog/2016/05/11/apache-spark-2-0-technical-preview-easier-faster-and-smarter.html">Technical Preview of Apache Spark 2.0 Now on Databricks</a></li>
  <li><a href="http://www.iteblog.com/archives/1673">Spark 2.0介绍：SparkSession创建和使用相关API</a></li>
  <li><a href="https://databricks-prod-cloudfront.cloud.databricks.com/public/4027ec902e239c93eaaa8714f173bcfc/6122906529858466/431554386690884/4814681571895601/latest.html">SparkSession - a new entry point</a></li>
  <li><a href="http://blog.madhukaraphatak.com/introduction-to-spark-two-part-1/">http://blog.madhukaraphatak.com/introduction-to-spark-two-part-1/</a></li>
  <li><a href="http://vishnuviswanath.com/spark_session.html">Experiment with Spark 2.0 - Session</a></li>
  <li><a href="http://spark.apache.org/docs/2.0.0-preview/">Spark Programming Guide of 2.0 Preview</a></li>
  <li><a href="http://www.iteblog.com/archives/tag/spark/page/2">Spark Series on Iteblog</a></li>
  <li><a href="https://databricks-prod-cloudfront.cloud.databricks.com/public/4027ec902e239c93eaaa8714f173bcfc/6122906529858466/293651311471490/5382278320999420/latest.html">Performance of Spark 2.0’s Tungsten engine</a></li>
  <li><a href="https://databricks.com/blog/2016/05/23/apache-spark-as-a-compiler-joining-a-billion-rows-per-second-on-a-laptop.html">Apache Spark as a Compiler: Joining a Billion Rows per Second on a Laptop : Deep dive into the new Tungsten execution engine</a></li>
  <li><a href="https://databricks-prod-cloudfront.cloud.databricks.com/public/4027ec902e239c93eaaa8714f173bcfc/6122906529858466/2727501386611546/5382278320999420/latest.html">Demo 2. SparkSession - the new entry point</a></li>
  <li><a href="https://databricks-prod-cloudfront.cloud.databricks.com/public/4027ec902e239c93eaaa8714f173bcfc/6122906529858466/431554386690871/4814681571895601/latest.html">Dataset API</a></li>
  <li><a href="https://databricks-prod-cloudfront.cloud.databricks.com/public/4027ec902e239c93eaaa8714f173bcfc/6122906529858466/100429797847215/4814681571895601/latest.html">Saving &amp; loading Machine Learning (ML) models</a></li>
  <li><a href="https://databricks-prod-cloudfront.cloud.databricks.com/public/4027ec902e239c93eaaa8714f173bcfc/2728434780191932/1483312212640900/6987336228780374/latest.html">Subqueries in Apache Spark 2.0</a></li>
</ul>

<h2 id="本系列文章链接">本系列文章链接</h2>

<ul>
  <li><a href="http://litaotao.github.io/introduction-to-spark?s=inner">『 Spark 』1. spark 简介 </a></li>
  <li><a href="http://litaotao.github.io/spark-questions-concepts?s=inner">『 Spark 』2. spark 基本概念解析 </a></li>
  <li><a href="http://litaotao.github.io/spark-programming-model?s=inner">『 Spark 』3. spark 编程模式 </a></li>
  <li><a href="http://litaotao.github.io/spark-what-is-rdd?s=inner">『 Spark 』4. spark 之 RDD </a></li>
  <li><a href="http://litaotao.github.io/spark-resouces-blogs-paper?s=inner">『 Spark 』5. 这些年，你不能错过的 spark 学习资源 </a></li>
  <li><a href="http://litaotao.github.io/deep-into-spark-exection-model?s=inner">『 Spark 』6. 深入研究 spark 运行原理之 job, stage, task</a></li>
  <li><a href="http://litaotao.github.io/spark-dataframe-introduction?s=inner">『 Spark 』7. 使用 Spark DataFrame 进行大数据分析</a></li>
  <li><a href="http://litaotao.github.io/spark-in-finance-and-investing?s=inner">『 Spark 』8. 实战案例 ｜ Spark 在金融领域的应用 ｜ 日内走势预测</a></li>
  <li><a href="http://litaotao.github.io/ipython-notebook-spark?s=inner">『 Spark 』9. 搭建 IPython + Notebook + Spark 开发环境</a></li>
  <li><a href="http://litaotao.github.io/boost-spark-application-performance?s=inner">『 Spark 』10. spark 应用程序性能优化｜12 个优化方法</a></li>
  <li><a href="http://litaotao.github.io/spark-mlib-machine-learning?s=inner">『 Spark 』11. spark 机器学习</a></li>
  <li><a href="http://litaotao.github.io/spark-2.0-faster-easier-smarter?s=inner">『 Spark 』12. Spark 2.0 特性介绍</a></li>
  <li><a href="http://litaotao.github.io/spark-2.0-release-notes-zh?s=inner">『 Spark 』13. Spark 2.0 Release Notes 中文版 </a></li>
  <li><a href="http://litaotao.github.io/spark-sql-parquet-optimize?s=inner">『 Spark 』14. 一次 Spark SQL 性能优化之旅</a></li>
</ul>


    <!-- share icon -->
    <!-- <div class="ds-share" data-thread-key="/spark-2.0-faster-easier-smarter" data-title="『 Spark 』12. Spark 2.0  | 10 个特性介绍"
         data-content="content"
         data-url="http://litaotao.github.io//spark-2.0-faster-easier-smarter">
        <div class="ds-share-aside-left">
          <div class="ds-share-aside-inner">
          </div>
          <div class="ds-share-aside-toggle">分享</div>
        </div>
    </div>
 -->
    <!-- 百度分享按钮 -->

<script>window._bd_share_config={"common":{"bdSnsKey":{},"bdText":"","bdMini":"1","bdMiniList":false,"bdPic":"","bdStyle":"0","bdSize":"16"},"slide":{"type":"slide","bdImg":"7","bdPos":"left","bdTop":"118"},"image":{"viewList":["weixin","qzone","tsina","tqq","renren","sqq","evernotecn","youdao"],"viewText":"分享到：","viewSize":"16"},"selectShare":{"bdContainerClass":null,"bdSelectMiniList":["weixin","qzone","tsina","tqq","renren","sqq","evernotecn","youdao"]}};with(document)0[(getElementsByTagName('head')[0]||body).appendChild(createElement('script')).src='http://bdimg.share.baidu.com/static/api/js/share.js?v=89860593.js?cdnversion='+~(-new Date()/36e5)];</script>


<!--     <div id="disqus_container">
      <div style="margin-bottom:20px">
      多说评论框 start
        <div class="ds-thread" data-thread-key=/spark-2.0-faster-easier-smarter data-title=『 Spark 』12. Spark 2.0  | 10 个特性介绍 
             data-url=http://localhost:4000+/spark-2.0-faster-easier-smarter></div>
      多说评论框 end
      多说公共JS代码 start (一个网页只需插入一次)
      <script type="text/javascript">
      var duoshuoQuery = {short_name:"litaotao"};
        (function() {
          var ds = document.createElement('script');
          ds.type = 'text/javascript';ds.async = true;
          // ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
          ds.src = '../js/embed.js'
          ds.charset = 'UTF-8';
          (document.getElementsByTagName('head')[0]
           || document.getElementsByTagName('body')[0]).appendChild(ds);
        })();
        </script>
      多说公共JS代码 end
      </div>
    </div> -->

        <div id="disqus_thread"></div>
            <script>

            /**
            *  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
            *  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables*/
            /*
            var disqus_config = function () {
            this.page.url = PAGE_URL;  // Replace PAGE_URL with your page's canonical URL variable
            this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
            };
            */
            (function() { // DON'T EDIT BELOW THIS LINE
            var d = document, s = d.createElement('script');
            s.src = 'https://litaotao-github-io.disqus.com/embed.js';
            s.setAttribute('data-timestamp', +new Date());
            (d.head || d.body).appendChild(s);
            })();
            </script>
            <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>    

  </div>
  
  <div id="menuIndex" class="sidenav">
    <div class="myinfo">
        <center>
          <div id="avatarHolder" class="avatar circle" style="width: 0px; height: 0px; box-shadow: none; margin-bottom: 20px;">
          </div>
          <a href="/index.html" title="Homepage"><i class="icon-home icon-large"></i> Home</a>
          <a href="http://www.linkedin.com/in/taotaoli"><i class="icon-linkedin-sign icon-large"></i> Linkedin</a>
          <a href="https://github.com/zxy"><i class="icon-github icon-large"></i> Code</a>
          <a href="mailto:1757943205@qq.com"><i class="icon-envelope icon-large"></i> Mail</a>
          <button id="present_button" onclick="present_mode()" style="width: 100%; margin-top: 10px; display: none"><i class="icon-align-justify icon-large"></i> Present Mode</button>
        </center>
    </div>
    <div id="menu"></div>
  </div>
</div>

<script src="/js/post.js" type="text/javascript"></script>
<script type="text/javascript">
    //博文页面也做一下刷新操作，避免有时候切换横竖屏时格式不对的问题  
    // $( window ).resize(function() { 
    //     location.reload(); 
    // });
</script>


  <script type="text/javascript">
    var cnzz_protocol = (("https:" == document.location.protocol) ? " https://" : " http://");
    document.write(unescape("%3Cspan id='cnzz_stat_icon_1258855744'%3E%3C/span%3E%3Cscript src='" + cnzz_protocol + "s11.cnzz.com/z_stat.php%3Fid%3D1258855744' type='text/javascript'%3E%3C/script%3E"));
  </script>

</body>
</html>
