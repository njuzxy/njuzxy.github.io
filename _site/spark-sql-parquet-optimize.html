<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8" />
  <title>『 Spark 』14. 一次 Spark SQL 性能提升10倍的经历 | 云在青天水在瓶</title>
  <meta name="baidu-site-verification" content="6b2f48c1baf35f9e0eb29b4455265203"/>
  <meta name="baidu-site-verification" content="hgXDOPtWLn" />
  <meta name="google-site-verification" content="YqjJD80rZQfugWoznvslaHlII_viwiMiUDEEgPTLEDw" />
  <meta name="renderer" content="webkit">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, minimum-scale=1.0">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="mobile-web-app-capable" content="yes">
  <link rel="stylesheet" href="/css/font-awesome/css/font-awesome.min.css" type="text/css" />
  <script src="/files/dc3da690b0d2a5655a8d6150862a2a07.html"></script>
  <!-- <link rel="stylesheet" href="/css/pygments.css" type="text/css" /> -->
  <link rel="stylesheet" href="/css/default-min.css" type="text/css" />
  <link rel="stylesheet" href="/css/desktop-min.css" type="text/css" />
  <link rel="stylesheet" href="/css/mobile-min.css" type="text/css" />
  <link rel="shortcut icon" href="/css/favicon.ico" type="image/x-icon" />
  <link rel="icon" href="/css/favicon.ico" mce_href="/favicon.ico" type="image/x-icon">
  <link rel="alternate" type="application/atom+xml" title="Recent Entries" href="/atom.xml" />
  <script src="/js/jquery-1.11.0.min.js" type="text/javascript"></script>
  <script src="/js/jquery-migrate-1.2.1.min.js" type="text/javascript"></script>
  <script src="/js/jquery.transit.min.js" type="text/javascript"></script>
  <script src="/js/common.js" type="text/javascript"></script>
  <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>

  
  <!-- growingIO code -->
  <script type='text/javascript'>
      var _vds = _vds || [];
      window._vds = _vds;
      (function(){
        _vds.push(['setAccountId', '9f3f34627219ccd1']);
        (function() {
          var vds = document.createElement('script');
          vds.type='text/javascript';
          vds.async = true;
          vds.src = ('https:' == document.location.protocol ? 'https://' : 'http://') + 'dn-growing.qbox.me/vds.js';
          var s = document.getElementsByTagName('script')[0];
          s.parentNode.insertBefore(vds, s);
        })();
      })();
  </script>
  
  <!-- 删掉 baidu spider 主动推送，无效 -->
  <!-- baidu spider initiative push -->
<!-- <script>
    (function(){
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';        
        }
        else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
  </script> -->
  
  <!-- google analytics push code -->
  <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-72176628-2', 'auto');
      ga('send', 'pageview');
  </script>

</head>

<!-- meiqia plug-in -->
<!-- 
<script type='text/javascript'>
    (function(m, ei, q, i, a, j, s) {
        m[a] = m[a] || function() {
            (m[a].a = m[a].a || []).push(arguments)
        };
        j = ei.createElement(q),
            s = ei.getElementsByTagName(q)[0];
        j.async = true;
        j.charset = 'UTF-8';
        j.src = i + '?v=' + new Date().getUTCDate();
        s.parentNode.insertBefore(j, s);
    })(window, document, 'script', '//static.meiqia.com/dist/meiqia.js', '_MEIQIA');
    _MEIQIA('entId', 15857);
</script>
 -->

<body>
  <link rel="stylesheet" href="/js/prettify/prettify.css" />
<style type="text/css">
  html {
    /*background: #333333;*/
    background: rgb(246, 246, 246);
    -webkit-background-size: cover;
    -moz-background-size: cover;
    -o-background-size: cover;
    background-size: cover;
  }
  /*body { background:transparent;}*/
  @media screen and (max-width: 770px){
    body { background: rgba(255, 255, 255, 0.9); }
  }
</style>

<div id="content" class="post" style="margin-top: 20px;">
  <div id="avatar" class="avatar circle" data-in-right="false" style="width: 150px; height: 150px; position: fixed; top: 40px; z-index: 99; opacity: 0;">
    <div class="center" style="margin-top: 4px; height: 142px; width: 142px; border-radius: 71px; background-image: url('../images/2.jpg');"></div>
  </div>

  <div class="entry" style="position: relative;">
    <h1 class="entry-title"><a href="/spark-sql-parquet-optimize" title="『 Spark 』14. 一次 Spark SQL 性能提升10倍的经历">『 Spark 』14. 一次 Spark SQL 性能提升10倍的经历</a></h1>    

    <p class="entry-date">2016-12-13 
        <span class="lastModified" style="display: none;" data-source="_posts/new-spark/2016-12-13-spark-sql-parquet-optimize.md">最后更新时间: 
        </span>
    </p>


    <h2 id="写在前面">写在前面</h2>

<p>本系列是综合了自己在学习spark过程中的理解记录 ＋ 对参考文章中的一些理解 ＋ 个人实践spark过程中的一些心得而来。写这样一个系列仅仅是为了梳理个人学习spark的笔记记录，所以一切以能够理解为主，没有必要的细节就不会记录了，而且文中有时候会出现英文原版文档，只要不影响理解，都不翻译了。若想深入了解，最好阅读参考文章和官方文档。</p>

<p>其次，本系列是基于目前最新的 spark 1.6.0 系列开始的，spark 目前的更新速度很快，记录一下版本号还是必要的。 <br />
最后，如果各位觉得内容有误，欢迎留言备注，所有留言 24 小时内必定回复，非常感谢。</p>

<p>Tips: 如果插图看起来不明显，可以：1. 放大网页；2. 新标签中打开图片，查看原图哦；3. 点击右边目录上方的 <em>present mode</em> 哦。</p>

<p><code class="highlighter-rouge">Notes</code>:</p>

<ul>
  <li>本篇开始，会渐渐的把版本升级到 2.0 上，后续的文章也会逐渐基于 2.0 来写；前面的文章就不改了，反正都是换汤不换药;</li>
</ul>

<p>上一篇文章： 
<a href="http://litaotao.github.io/spark-2.0-release-notes-zh?s=inner">『 Spark 』13. Spark 2.0 Release Notes 中文版 </a></p>

<h2 id="1-遇到了啥问题">1. 遇到了啥问题</h2>

<p>是酱紫的，简单来说：并发执行 spark job 的时候，并发的提速很不明显。</p>

<p><img src="../images/what_are_you_talking_about.png" alt="what_are_you_talking_about.png" /></p>

<p>嗯，且听我慢慢道来，啰嗦点说，类似于我们内部有一个系统给分析师用，他们写一些 sql，在我们的 spark cluster 上跑。随着分析师越来越多，sql job 也越来越多，等待运行的时间也越来越长，我们就在想怎么把 sql 运行的时间加快一点。我们的整个架构是 spark 1.6.1 on YARN 的，经过分析一些 sql 发现其实大多数分析语句都是比较简单的统计 sql，集群资源也还算多，一条简单的 sql 语句就把整个集群资源的坑占着略显不合适，有点飞机马达装到拖拉机上的赶脚，所以第一步，我们想，支持 spark job 的并行运行。</p>

<p>ok，初步方案有了，我们就做了如下几步改善工作：</p>

<ul>
  <li>
    <p>首先设置 <code class="highlighter-rouge">spark.scheduler.mode</code> 为 <code class="highlighter-rouge">FAIR</code> 模式，首先 <code class="highlighter-rouge">spark.scheduler.mode</code> 有 <code class="highlighter-rouge">FIFO</code>, <code class="highlighter-rouge">FAIR</code> 两种模式，<code class="highlighter-rouge">FIFO</code> 是说提交的job，都是顺序执行的，后提交的 job 一定要等之前提交的 job 完全执行结束后才可以执行；<code class="highlighter-rouge">FAIR</code> 是说，如果之前提交的 job 没有用完集群资源的话，后提交的job可以即刻开始运行。关于这点在官方文档上有详细的解释：</p>

    <p><img src="../images/schedule_mode.png" alt="schedule_mode.png" /></p>
  </li>
  <li>
    <p>其次，我们生成了 10 个 pool，所谓的 pool，可以理解为资源池，或者通道。你可以在提交 job 的时候指定提交到哪个 pool 里面，可以简单的理解为我们把所有的集群资源分成 10 份，然后在提交 job 的时候指定在哪一份资源中运行这个 job。</p>

    <p><img src="../images/10_pool.png" alt="10_pool.png" /></p>
  </li>
  <li>
    <p>最后，我们在提交 job 的时候指定提交到的 pool 名字，只需要在提交 job 之前设置一个 sparkContext 的参数即可: <code class="highlighter-rouge">sc.setLocalProperty("spark.scheduler.pool", "your_pool_id")</code></p>

    <p><img src="../images/pool_id.png" alt="pool_id.png" /></p>
  </li>
</ul>

<p>看似很简单，但能知道上面这些配置的也算是用 spark 比较熟练的人了吧，我迫不及待的测试了一下速度，发现了一个从古至今的大真理：理想很美好，现实很骨干啊。测试下来，发现多个 job 并行运行的时间并没有节省多少。</p>

<h2 id="2-原因排查">2. 原因排查</h2>

<p>上面把问题说得很清楚了：多 job 并行的时候，运行速度并没有明显提升。但是原理上应该不会如此，只要一个 sql job 不需要全局所有集群资源，理论上来说会有较大提升的。下面是一组简单的数据对比：</p>

<p><img src="../images/data_contrast_1.png" alt="data_contrast_1.png" /></p>

<p>虽然看到，并行计算后时间只需要之前的 50%，但是这里需要说明一下，这个数据不够稳定的哦，比如说偶尔会新增 10来秒 这样子的。这里 <code class="highlighter-rouge">暂且接受提升 50% 的速度这样一个结论吧</code>。</p>

<p>但是，理论上来说，还能提升更多，不满足 50% 的提升效率，我们接着深度解读 spark web ui 上的一些分析数据，尝试找找能否把速度再度提升一下。终于找到了核心原因，下面我就把整个排查的过程详细记录下来：</p>

<ul>
  <li>
    <p>找一个花费时间较长的 job，进去看看执行的详情，这里我们用 job id 为 796 的这个 job</p>

    <p><img src="../images/spark_optimize_1.png" alt="spark_optimize_1.png" /></p>
  </li>
  <li>
    <p>发现 job 796 有两个 stage，且有 99% 的时间都花在第一个 stage 1590 上了，而且需要注意的是，这个 stage 有 237.6mb 的数据读取，有可能需要经过网络从其他 hdfs 节点读过来，难道跟网络 I/O 有关？继续点进去看看。</p>

    <p><img src="../images/spark_optimize_2.png" alt="spark_optimize_2.png" /></p>
  </li>
  <li>
    <p>进来这个 stage 内部，似乎发现问题所在了，首先我们先关注下图中标记的几个点，可以总结出几个点：</p>
    <ul>
      <li>首先，该 stage 内的所有任务在 executor 上真正执行的时间【可以理解为 cpu time】是 2s</li>
      <li>其次，该 stage 内任务执行完成的时间是 1.1 m，大概是 66s，可以理解为【wall time】</li>
      <li>该 stage 内所有的 task，<code class="highlighter-rouge">schedule delay</code> 的时间中位数是 0.5s，最大达到 1s【真正执行的时间也才 2s 哦】</li>
      <li>该 stage 内一共有 336 个task</li>
    </ul>

    <p><img src="../images/spark_optimize_3.png" alt="spark_optimize_3.png" />
  <img src="../images/spark_optimize_4.png" alt="spark_optimize_4.png" /></p>
  </li>
</ul>

<p>到这里，问题根源基本上已经知道了，即 job 796 的大多数时间都被消耗在 stage 1590 的 336 个task 的 secheduler delay 上面了。</p>

<h2 id="3-如何解决">3. 如何解决</h2>

<p>上面问题几乎已经明确了，现在就该看看肿么解决了。我当时是这样去考虑的：</p>

<ul>
  <li>为什么 scheduler delay 会这么大</li>
</ul>

<blockquote>
  <p>因为资源不够，要解决这个问题，似乎唯一的办法就是增加集群资源了。可是哥们，集群是你想加就能加的吗？那可是要砸钱的呀？而且如果公司缺机器的话，想加集群资源也要经过 申请-&gt;审批-&gt;采购-&gt;分配-&gt;集群配置 大大小小几个阶段，说不一定等你找到女朋友了都还没搞定啊。</p>
</blockquote>

<p>当时想着加资源这个方案短期不可取后，有那么几分钟是觉得有点烧脑的。我就静静的看着 web ui，心里在算，一个 task 如果平均 scheduler delay 0.5s 的话，这 336 个 task 就得 delay 118 秒，基本上都到 2 分钟了。这 delay 的时间可真够长的啊，就在算这个数值的时候，突然想到这样一个公式：<code class="highlighter-rouge">total delay time = average delay time * task number</code>。现在我们的问题是要解决 total delay time，那完全可以从两方面去解决呀：</p>

<ul>
  <li>降低 average delay time：目前来看似乎唯一的方法是砸钱加资源</li>
  <li>降低 task 数：粗略来看，简单的降低 task 数的话，应该是能减少 total delay time 的，但是如果task 数降低了，意味着每个 task 需要处理的数据量就多了，那其他的时间应该是会增加一些的，比如说 <code class="highlighter-rouge">Task Deserialization Time, Result Serialization Time, GC Time, Duration</code> 等。减少 task 数究竟能不能提高整体运行速度，似乎乍一看还真不好确定。</li>
</ul>

<p>反正砸钱加资源这个方案暂时是行不通的，要不就再仔细分析一下降低task数这个方案。这里我们在仔细参考一下下图中这一列指标：</p>

<p><img src="../images/spark_optimize_5.png" alt="spark_optimize_5.png" />
<img src="../images/spark_optimize_6.png" alt="spark_optimize_6.png" /></p>

<p>我们用 75 分位的统计数据来做一个假设：假设我们把每一个 task 的数据量加 10 倍，那么预计的 task metrics 75 分位大概是一个什么样的数值，假设这些指标都是线性增长的话：</p>

<ul>
  <li>Duration: 扩大到 10 倍，14ms</li>
  <li>Scheduler Delay: 这个指标不用估计</li>
  <li>Task Deserialization Time: 扩大到 10 倍，6ms</li>
  <li>GC Time: 扩大到 10 倍，最多1ms</li>
  <li>Result Serialization Time: 扩大到 10 倍，最多1ms</li>
  <li>Getting Result Time: 扩大到 10 倍，最多1ms</li>
  <li>Peak Execution Memory: 扩大到 10 倍，最多 1b</li>
  <li>Input Size / Records: 扩大到 10 倍，918.8 KB * 2 / 2</li>
  <li>Shuffle Write Size / Records  0: 扩大到 10 倍，294.0 B * 2/ 20</li>
</ul>

<p>可以看到，这样大概估计下来，除去 Scheduler Delay 的时间，其实其他时间也没消耗多少，都是毫秒级的，看起来应该是完全可行的呀。</p>

<p>正准备这样测试的时候，我忽然想到，为什么现在的 metrics 统计是这样的结构的啊，这么多 task？一般来说，一个 task 对应到 hdfs 上的一个 parquet 文件【该项目中所有数据文件都是用 parquet 压缩后存储到 hdfs 上的】，难道是现在存在 hdfs 上的 parquet 文件个数过多，每个文件太小？突然有一种恍然大悟的感觉，赶紧看看现在 hdfs 上文件的结构，如下所示：</p>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell">taotao@mac007:~/Desktop/dyes/git-mercury/mercury-computing<span class="nv">$hadoop</span> fs <span class="nt">-ls</span> <span class="nt">-h</span> hdfs://hadoop-archive-cluster/hfmkt/level2/datayes/parquet/20161117/20161117_Transaction_SZ | <span class="nb">cat</span> <span class="nt">-n</span> | <span class="nb">tail
</span>317  <span class="nt">-rw-r--r--</span>   3 taotao hfmkt      1.3 M 2016-11-17 16:37 hdfs://hadoop-archive-cluster/hfmkt/level2/datayes/parquet/20161117/20161117_Transaction_SZ/part-r-00310-38d7cc53-60d2-40b3-a945-0cb5832f30de.gz.parquet
318  <span class="nt">-rw-r--r--</span>   3 taotao hfmkt      1.4 M 2016-11-17 16:37 hdfs://hadoop-archive-cluster/hfmkt/level2/datayes/parquet/20161117/20161117_Transaction_SZ/part-r-00311-38d7cc53-60d2-40b3-a945-0cb5832f30de.gz.parquet
319  <span class="nt">-rw-r--r--</span>   3 taotao hfmkt      2.9 M 2016-11-17 16:37 hdfs://hadoop-archive-cluster/hfmkt/level2/datayes/parquet/20161117/20161117_Transaction_SZ/part-r-00312-38d7cc53-60d2-40b3-a945-0cb5832f30de.gz.parquet
320  <span class="nt">-rw-r--r--</span>   3 taotao hfmkt      1.2 M 2016-11-17 16:37 hdfs://hadoop-archive-cluster/hfmkt/level2/datayes/parquet/20161117/20161117_Transaction_SZ/part-r-00313-38d7cc53-60d2-40b3-a945-0cb5832f30de.gz.parquet
321  <span class="nt">-rw-r--r--</span>   3 taotao hfmkt      1.9 M 2016-11-17 16:37 hdfs://hadoop-archive-cluster/hfmkt/level2/datayes/parquet/20161117/20161117_Transaction_SZ/part-r-00314-38d7cc53-60d2-40b3-a945-0cb5832f30de.gz.parquet
322  <span class="nt">-rw-r--r--</span>   3 taotao hfmkt      1.7 M 2016-11-17 16:37 hdfs://hadoop-archive-cluster/hfmkt/level2/datayes/parquet/20161117/20161117_Transaction_SZ/part-r-00315-38d7cc53-60d2-40b3-a945-0cb5832f30de.gz.parquet
323  <span class="nt">-rw-r--r--</span>   3 taotao hfmkt    899.4 K 2016-11-17 16:37 hdfs://hadoop-archive-cluster/hfmkt/level2/datayes/parquet/20161117/20161117_Transaction_SZ/part-r-00316-38d7cc53-60d2-40b3-a945-0cb5832f30de.gz.parquet
324  <span class="nt">-rw-r--r--</span>   3 taotao hfmkt      2.3 M 2016-11-17 16:37 hdfs://hadoop-archive-cluster/hfmkt/level2/datayes/parquet/20161117/20161117_Transaction_SZ/part-r-00317-38d7cc53-60d2-40b3-a945-0cb5832f30de.gz.parquet
325  <span class="nt">-rw-r--r--</span>   3 taotao hfmkt      1.0 M 2016-11-17 16:37 hdfs://hadoop-archive-cluster/hfmkt/level2/datayes/parquet/20161117/20161117_Transaction_SZ/part-r-00318-38d7cc53-60d2-40b3-a945-0cb5832f30de.gz.parquet
326  <span class="nt">-rw-r--r--</span>   3 taotao hfmkt    460.9 K 2016-11-17 16:37 hdfs://hadoop-archive-cluster/hfmkt/level2/datayes/parquet/20161117/20161117_Transaction_SZ/part-r-00319-38d7cc53-60d2-40b3-a945-0cb5832f30de.gz.parquet</code></pre></figure>

<p>可以看到，现在有 300 多个文件【上面只是一部分，还有十几个在另外一个文件夹里，一个 sql 会统计两个文件夹里的数据文件】，而且我仔细看了一下，每个文件大小最小的有很多 1kb 的，最大的有 2.9mb 的。难怪了，原来核心根源在这里。再结合上面关于 metrics 的分析，我心里大概确信了，只要把 parquet 文件的问题解决就行了，方法就是压缩 parquet 文件个数，控制每个 parquet 文件的大小即可。</p>

<p><img src="../images/bingo.png" alt="bingo.png" /></p>

<p>方法确定了，那就干咯。</p>

<h2 id="4-效果对比">4. 效果对比</h2>

<p>未来方便对比，我把 20161212 的数据文件处理了一下，保留 20161117 这天的数据文件【20161212 的数据文件整体上比 20161117 的数据文件要多 10%】，下面是对比结果：</p>

<p><strong><em>parquet 文件个数</em></strong></p>

<ul>
  <li>20161117 这天</li>
</ul>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell">taotao@mac007:~/Desktop/dyes/git-mercury/mercury-computing<span class="nv">$hadoop</span> fs <span class="nt">-ls</span> <span class="nt">-h</span> hdfs://hadoop-archive-cluster/hfmkt/level2/datayes/parquet/20161117/20161117_Transaction_S<span class="k">*</span> | <span class="nb">cat</span> <span class="nt">-n</span> | <span class="nb">tail</span> <span class="nt">-n</span> 5
342  <span class="nt">-rw-r--r--</span>   3 taotao hfmkt      1.7 M 2016-11-17 16:37 hdfs://hadoop-archive-cluster/hfmkt/level2/datayes/parquet/20161117/20161117_Transaction_SZ/part-r-00315-38d7cc53-60d2-40b3-a945-0cb5832f30de.gz.parquet
343  <span class="nt">-rw-r--r--</span>   3 taotao hfmkt    899.4 K 2016-11-17 16:37 hdfs://hadoop-archive-cluster/hfmkt/level2/datayes/parquet/20161117/20161117_Transaction_SZ/part-r-00316-38d7cc53-60d2-40b3-a945-0cb5832f30de.gz.parquet
344  <span class="nt">-rw-r--r--</span>   3 taotao hfmkt      2.3 M 2016-11-17 16:37 hdfs://hadoop-archive-cluster/hfmkt/level2/datayes/parquet/20161117/20161117_Transaction_SZ/part-r-00317-38d7cc53-60d2-40b3-a945-0cb5832f30de.gz.parquet
345  <span class="nt">-rw-r--r--</span>   3 taotao hfmkt      1.0 M 2016-11-17 16:37 hdfs://hadoop-archive-cluster/hfmkt/level2/datayes/parquet/20161117/20161117_Transaction_SZ/part-r-00318-38d7cc53-60d2-40b3-a945-0cb5832f30de.gz.parquet
346  <span class="nt">-rw-r--r--</span>   3 taotao hfmkt    460.9 K 2016-11-17 16:37 hdfs://hadoop-archive-cluster/hfmkt/level2/datayes/parquet/20161117/20161117_Transaction_SZ/part-r-00319-38d7cc53-60d2-40b3-a945-0cb5832f30de.gz.parquet</code></pre></figure>

<ul>
  <li>20161212 这天</li>
</ul>

<figure class="highlight"><pre><code class="language-shell" data-lang="shell">taotao@mac007:~/Desktop/dyes/git-mercury/mercury-computing<span class="nv">$hadoop</span> fs <span class="nt">-ls</span> <span class="nt">-h</span> hdfs://hadoop-archive-cluster/hfmkt/level2/datayes/parquet/20161212/20161212_Transaction_S<span class="k">*</span> | <span class="nb">cat</span> <span class="nt">-n</span> | <span class="nb">tail</span> <span class="nt">-n</span> 5
34  <span class="nt">-rw-r--r--</span>   3 taotao hfmkt     19.2 M 2016-12-12 15:49 hdfs://hadoop-archive-cluster/hfmkt/level2/datayes/parquet/20161212/20161212_Transaction_SZ/part-r-00013-686bbce5-a7a1-4b5d-b25c-14cd9ddae283.gz.parquet
35  <span class="nt">-rw-r--r--</span>   3 taotao hfmkt     10.7 M 2016-12-12 15:49 hdfs://hadoop-archive-cluster/hfmkt/level2/datayes/parquet/20161212/20161212_Transaction_SZ/part-r-00014-686bbce5-a7a1-4b5d-b25c-14cd9ddae283.gz.parquet
36  <span class="nt">-rw-r--r--</span>   3 taotao hfmkt     26.0 M 2016-12-12 15:49 hdfs://hadoop-archive-cluster/hfmkt/level2/datayes/parquet/20161212/20161212_Transaction_SZ/part-r-00015-686bbce5-a7a1-4b5d-b25c-14cd9ddae283.gz.parquet
37  <span class="nt">-rw-r--r--</span>   3 taotao hfmkt     20.1 M 2016-12-12 15:49 hdfs://hadoop-archive-cluster/hfmkt/level2/datayes/parquet/20161212/20161212_Transaction_SZ/part-r-00016-686bbce5-a7a1-4b5d-b25c-14cd9ddae283.gz.parquet
38  <span class="nt">-rw-r--r--</span>   3 taotao hfmkt      8.7 M 2016-12-12 15:49 hdfs://hadoop-archive-cluster/hfmkt/level2/datayes/parquet/20161212/20161212_Transaction_SZ/part-r-00017-686bbce5-a7a1-4b5d-b25c-14cd9ddae283.gz.parquet</code></pre></figure>

<p><strong><em>100个job并发执行时间</em></strong></p>

<ul>
  <li>20161117 这天：99s</li>
  <li>20161212 这天：16s</li>
</ul>

<p><strong><em>Spark Web UI 上一个 job 对比</em></strong></p>

<ul>
  <li>20161117 这天</li>
</ul>

<p><img src="../images/spark_optimize_2.png" alt="spark_optimize_2.png" />
<img src="../images/spark_optimize_3.png" alt="spark_optimize_3.png" />
<img src="../images/spark_optimize_4.png" alt="spark_optimize_4.png" /></p>

<ul>
  <li>20161212 这天</li>
</ul>

<p><img src="../images/spark_optimize_7.png" alt="spark_optimize_7.png" />
<img src="../images/spark_optimize_9.png" alt="spark_optimize_9.png" />
<img src="../images/spark_optimize_8.png" alt="spark_optimize_8.png" /></p>

<h2 id="5-总结">5. 总结</h2>

<p>首先，需要说明的是，这次优化应该还有提升的空间，虽然优化后整体从 204s 到 99s 再到 16s，提升了十倍多，确实很大，但是最后我们还是发现 16s 的情况下，scheduler delay 和 Task Deserialization Time 还是有占用了大部分时间，这里我觉得不能一味的在文件个数和大小上下功夫了。需要考虑到用户场景来做一个权衡。所以越到后期的优化，越考验产品功能的设计，当然这是后话了，就不在本文范围内讨论。</p>

<p>其次，这次优化，从发现问题，追根溯源，到最后解决问题，大概花了 1 小时，基本上还算不错。通过这次排查，还是真心感受到 spark 设计的完善，不得不说，作为一个开源项目，spark 最大的特点，我觉得应该是 spark 是由一帮非程序员设计实现的，而是一帮由程序员，架构师，产品经理组合起来一起干的，更像是一个产品，而不是一个开源项目。怪不得这帮人要去开个公司【databricks：我最看好的公司之一】，看来真的是 born this way。说到这，不得不感触一下，对比 spark 这帮人，现实中真的有太多指令式程序员了，老板叫干嘛就干嘛，丝毫不关注产品功能，未来发展，甚至很多工程师都不用自己开发的产品。我不知道这样的人是怎么想的，反正我自己觉得这样挺可怜的。</p>

<p>最后，好久都没写 spark 相关的文章了，距离上一片水文过去整整两个月了。最近两个月真心累成狗了，要做好项目，关注竞品的发展，行业动态；还要经常出去拜访客户，维护客户；同时也要做好产品未来几个月甚至几个季度的规划，偶尔还要搞搞运营啥的。文章写少了，但视野真心见长了，anyway，未来再接着抽空多记录点文字下来，哈哈。</p>

<h2 id="6-打开微信扫一扫点一点棒棒的_">6. 打开微信，扫一扫，点一点，棒棒的，^_^</h2>

<p><img src="../images/wechat_pay_6-6.png" alt="wechat_pay_6-6.png" /></p>

<h2 id="参考文章">参考文章</h2>

<ul>
  <li><a href="https://parquet.apache.org/documentation/latest/">Apache Parquet</a></li>
  <li><a href="http://spark.apache.org/docs/latest/job-scheduling.html#scheduling-within-an-application">scheduling-within-an-application</a></li>
  <li><a href="http://spark.apache.org/docs/latest/configuration.html#scheduling">configuration scheduling</a></li>
  <li><a href="https://spark.apache.org/docs/latest/job-scheduling.html#configuring-pool-properties">job-scheduling.html configuring-pool-properties</a></li>
  <li><a href="http://www.cnblogs.com/yurunmiao/p/5195754.html">Spark使用CombineTextInputFormat缓解小文件过多导致Task数目过多的问题</a></li>
  <li><a href="http://blog.cloudera.com/blog/2009/02/the-small-files-problem/">The Small Files Problem</a></li>
  <li><a href="https://forums.databricks.com/questions/1509/parquet-file-merging-or-other-optimisation-tips.html">Parquet file merging or other optimisation tips</a></li>
  <li><a href="https://spark-summit.org/2015/events/data-storage-tips-for-optimal-spark-performance/">Data Storage Tips for Optimal Spark Performance</a></li>
</ul>

<h2 id="本系列文章链接">本系列文章链接</h2>

<ul>
  <li><a href="http://litaotao.github.io/introduction-to-spark?s=inner">『 Spark 』1. spark 简介 </a></li>
  <li><a href="http://litaotao.github.io/spark-questions-concepts?s=inner">『 Spark 』2. spark 基本概念解析 </a></li>
  <li><a href="http://litaotao.github.io/spark-programming-model?s=inner">『 Spark 』3. spark 编程模式 </a></li>
  <li><a href="http://litaotao.github.io/spark-what-is-rdd?s=inner">『 Spark 』4. spark 之 RDD </a></li>
  <li><a href="http://litaotao.github.io/spark-resouces-blogs-paper?s=inner">『 Spark 』5. 这些年，你不能错过的 spark 学习资源 </a></li>
  <li><a href="http://litaotao.github.io/deep-into-spark-exection-model?s=inner">『 Spark 』6. 深入研究 spark 运行原理之 job, stage, task</a></li>
  <li><a href="http://litaotao.github.io/spark-dataframe-introduction?s=inner">『 Spark 』7. 使用 Spark DataFrame 进行大数据分析</a></li>
  <li><a href="http://litaotao.github.io/spark-in-finance-and-investing?s=inner">『 Spark 』8. 实战案例 ｜ Spark 在金融领域的应用 ｜ 日内走势预测</a></li>
  <li><a href="http://litaotao.github.io/ipython-notebook-spark?s=inner">『 Spark 』9. 搭建 IPython + Notebook + Spark 开发环境</a></li>
  <li><a href="http://litaotao.github.io/boost-spark-application-performance?s=inner">『 Spark 』10. spark 应用程序性能优化｜12 个优化方法</a></li>
  <li><a href="http://litaotao.github.io/spark-mlib-machine-learning?s=inner">『 Spark 』11. spark 机器学习</a></li>
  <li><a href="http://litaotao.github.io/spark-2.0-faster-easier-smarter?s=inner">『 Spark 』12. Spark 2.0 特性介绍</a></li>
  <li><a href="http://litaotao.github.io/spark-2.0-release-notes-zh?s=inner">『 Spark 』13. Spark 2.0 Release Notes 中文版 </a></li>
  <li><a href="http://litaotao.github.io/spark-sql-parquet-optimize?s=inner">『 Spark 』14. 一次 Spark SQL 性能优化之旅</a></li>
</ul>


    <!-- share icon -->
    <!-- <div class="ds-share" data-thread-key="/spark-sql-parquet-optimize" data-title="『 Spark 』14. 一次 Spark SQL 性能提升10倍的经历"
         data-content="content"
         data-url="http://litaotao.github.io//spark-sql-parquet-optimize">
        <div class="ds-share-aside-left">
          <div class="ds-share-aside-inner">
          </div>
          <div class="ds-share-aside-toggle">分享</div>
        </div>
    </div>
 -->
    <!-- 百度分享按钮 -->

<script>window._bd_share_config={"common":{"bdSnsKey":{},"bdText":"","bdMini":"1","bdMiniList":false,"bdPic":"","bdStyle":"0","bdSize":"16"},"slide":{"type":"slide","bdImg":"7","bdPos":"left","bdTop":"118"},"image":{"viewList":["weixin","qzone","tsina","tqq","renren","sqq","evernotecn","youdao"],"viewText":"分享到：","viewSize":"16"},"selectShare":{"bdContainerClass":null,"bdSelectMiniList":["weixin","qzone","tsina","tqq","renren","sqq","evernotecn","youdao"]}};with(document)0[(getElementsByTagName('head')[0]||body).appendChild(createElement('script')).src='http://bdimg.share.baidu.com/static/api/js/share.js?v=89860593.js?cdnversion='+~(-new Date()/36e5)];</script>


<!--     <div id="disqus_container">
      <div style="margin-bottom:20px">
      多说评论框 start
        <div class="ds-thread" data-thread-key=/spark-sql-parquet-optimize data-title=『 Spark 』14. 一次 Spark SQL 性能提升10倍的经历 
             data-url=http://localhost:4000+/spark-sql-parquet-optimize></div>
      多说评论框 end
      多说公共JS代码 start (一个网页只需插入一次)
      <script type="text/javascript">
      var duoshuoQuery = {short_name:"litaotao"};
        (function() {
          var ds = document.createElement('script');
          ds.type = 'text/javascript';ds.async = true;
          // ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
          ds.src = '../js/embed.js'
          ds.charset = 'UTF-8';
          (document.getElementsByTagName('head')[0]
           || document.getElementsByTagName('body')[0]).appendChild(ds);
        })();
        </script>
      多说公共JS代码 end
      </div>
    </div> -->

        <div id="disqus_thread"></div>
            <script>

            /**
            *  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
            *  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables*/
            /*
            var disqus_config = function () {
            this.page.url = PAGE_URL;  // Replace PAGE_URL with your page's canonical URL variable
            this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
            };
            */
            (function() { // DON'T EDIT BELOW THIS LINE
            var d = document, s = d.createElement('script');
            s.src = 'https://litaotao-github-io.disqus.com/embed.js';
            s.setAttribute('data-timestamp', +new Date());
            (d.head || d.body).appendChild(s);
            })();
            </script>
            <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>    

  </div>
  
  <div id="menuIndex" class="sidenav">
    <div class="myinfo">
        <center>
          <div id="avatarHolder" class="avatar circle" style="width: 0px; height: 0px; box-shadow: none; margin-bottom: 20px;">
          </div>
          <a href="/index.html" title="Homepage"><i class="icon-home icon-large"></i> Home</a>
          <a href="http://www.linkedin.com/in/taotaoli"><i class="icon-linkedin-sign icon-large"></i> Linkedin</a>
          <a href="https://github.com/zxy"><i class="icon-github icon-large"></i> Code</a>
          <a href="mailto:1757943205@qq.com"><i class="icon-envelope icon-large"></i> Mail</a>
          <button id="present_button" onclick="present_mode()" style="width: 100%; margin-top: 10px; display: none"><i class="icon-align-justify icon-large"></i> Present Mode</button>
        </center>
    </div>
    <div id="menu"></div>
  </div>
</div>

<script src="/js/post.js" type="text/javascript"></script>
<script type="text/javascript">
    //博文页面也做一下刷新操作，避免有时候切换横竖屏时格式不对的问题  
    // $( window ).resize(function() { 
    //     location.reload(); 
    // });
</script>


  <script type="text/javascript">
    var cnzz_protocol = (("https:" == document.location.protocol) ? " https://" : " http://");
    document.write(unescape("%3Cspan id='cnzz_stat_icon_1258855744'%3E%3C/span%3E%3Cscript src='" + cnzz_protocol + "s11.cnzz.com/z_stat.php%3Fid%3D1258855744' type='text/javascript'%3E%3C/script%3E"));
  </script>

</body>
</html>
