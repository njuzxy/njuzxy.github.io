<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8" />
  <title>『 Spark 』13. Spark 2.0 Release Notes 中文版 | 云在青天水在瓶</title>
  <meta name="baidu-site-verification" content="6b2f48c1baf35f9e0eb29b4455265203"/>
  <meta name="baidu-site-verification" content="hgXDOPtWLn" />
  <meta name="google-site-verification" content="YqjJD80rZQfugWoznvslaHlII_viwiMiUDEEgPTLEDw" />
  <meta name="renderer" content="webkit">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, minimum-scale=1.0">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="mobile-web-app-capable" content="yes">
  <link rel="stylesheet" href="/css/font-awesome/css/font-awesome.min.css" type="text/css" />
  <script src="/files/dc3da690b0d2a5655a8d6150862a2a07.html"></script>
  <!-- <link rel="stylesheet" href="/css/pygments.css" type="text/css" /> -->
  <link rel="stylesheet" href="/css/default-min.css" type="text/css" />
  <link rel="stylesheet" href="/css/desktop-min.css" type="text/css" />
  <link rel="stylesheet" href="/css/mobile-min.css" type="text/css" />
  <link rel="shortcut icon" href="/css/favicon.ico" type="image/x-icon" />
  <link rel="icon" href="/css/favicon.ico" mce_href="/favicon.ico" type="image/x-icon">
  <link rel="alternate" type="application/atom+xml" title="Recent Entries" href="/atom.xml" />
  <script src="/js/jquery-1.11.0.min.js" type="text/javascript"></script>
  <script src="/js/jquery-migrate-1.2.1.min.js" type="text/javascript"></script>
  <script src="/js/jquery.transit.min.js" type="text/javascript"></script>
  <script src="/js/common.js" type="text/javascript"></script>
  <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>

  
  <!-- growingIO code -->
  <script type='text/javascript'>
      var _vds = _vds || [];
      window._vds = _vds;
      (function(){
        _vds.push(['setAccountId', '9f3f34627219ccd1']);
        (function() {
          var vds = document.createElement('script');
          vds.type='text/javascript';
          vds.async = true;
          vds.src = ('https:' == document.location.protocol ? 'https://' : 'http://') + 'dn-growing.qbox.me/vds.js';
          var s = document.getElementsByTagName('script')[0];
          s.parentNode.insertBefore(vds, s);
        })();
      })();
  </script>
  
  <!-- 删掉 baidu spider 主动推送，无效 -->
  <!-- baidu spider initiative push -->
<!-- <script>
    (function(){
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';        
        }
        else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
  </script> -->
  
  <!-- google analytics push code -->
  <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-72176628-2', 'auto');
      ga('send', 'pageview');
  </script>

</head>

<!-- meiqia plug-in -->
<!-- 
<script type='text/javascript'>
    (function(m, ei, q, i, a, j, s) {
        m[a] = m[a] || function() {
            (m[a].a = m[a].a || []).push(arguments)
        };
        j = ei.createElement(q),
            s = ei.getElementsByTagName(q)[0];
        j.async = true;
        j.charset = 'UTF-8';
        j.src = i + '?v=' + new Date().getUTCDate();
        s.parentNode.insertBefore(j, s);
    })(window, document, 'script', '//static.meiqia.com/dist/meiqia.js', '_MEIQIA');
    _MEIQIA('entId', 15857);
</script>
 -->

<body>
  <link rel="stylesheet" href="/js/prettify/prettify.css" />
<style type="text/css">
  html {
    /*background: #333333;*/
    background: rgb(246, 246, 246);
    -webkit-background-size: cover;
    -moz-background-size: cover;
    -o-background-size: cover;
    background-size: cover;
  }
  /*body { background:transparent;}*/
  @media screen and (max-width: 770px){
    body { background: rgba(255, 255, 255, 0.9); }
  }
</style>

<div id="content" class="post" style="margin-top: 20px;">
  <div id="avatar" class="avatar circle" data-in-right="false" style="width: 150px; height: 150px; position: fixed; top: 40px; z-index: 99; opacity: 0;">
    <div class="center" style="margin-top: 4px; height: 142px; width: 142px; border-radius: 71px; background-image: url('../images/2.jpg');"></div>
  </div>

  <div class="entry" style="position: relative;">
    <h1 class="entry-title"><a href="/spark-2.0-release-notes-zh" title="『 Spark 』13. Spark 2.0 Release Notes 中文版">『 Spark 』13. Spark 2.0 Release Notes 中文版</a></h1>    

    <p class="entry-date">2016-09-13 
        <span class="lastModified" style="display: none;" data-source="_posts/new-spark/2016-09-13-spark-2.0-release-notes-zh.md">最后更新时间: 
        </span>
    </p>


    <h2 id="写在前面">写在前面</h2>

<p>本系列是综合了自己在学习spark过程中的理解记录 ＋ 对参考文章中的一些理解 ＋ 个人实践spark过程中的一些心得而来。写这样一个系列仅仅是为了梳理个人学习spark的笔记记录，所以一切以能够理解为主，没有必要的细节就不会记录了，而且文中有时候会出现英文原版文档，只要不影响理解，都不翻译了。若想深入了解，最好阅读参考文章和官方文档。</p>

<p>其次，本系列是基于目前最新的 spark 1.6.0 系列开始的，spark 目前的更新速度很快，记录一下版本号还是必要的。 <br />
最后，如果各位觉得内容有误，欢迎留言备注，所有留言 24 小时内必定回复，非常感谢。</p>

<p>Tips: 如果插图看起来不明显，可以：1. 放大网页；2. 新标签中打开图片，查看原图哦；3. 点击右边目录上方的 <em>present mode</em> 哦。</p>

<p><code class="highlighter-rouge">Notes</code>:</p>

<ul>
  <li>本篇开始，会渐渐的把版本升级到 2.0 上，后续的文章也会逐渐基于 2.0 来写；前面的文章就不改了，反正都是换汤不换药;</li>
  <li>本篇是上一篇文章的升级版，关于 spark 2.0 的大概介绍可以直接看上一篇文章，本篇文章是因为最近项目准备从 1.6.1 升级到 2.0，需要对 2.0 有一个整体的了解，所以索性读一遍 2.0 的 release notes，也随手把 release notes 的中文版写下来咯;</li>
  <li>虽说是中文版，但是一切都是以能理解为主，有的地方不知道怎么翻译，或者我觉得没有必要翻译的，就没有写成中文了，当然欢迎大家提出修改建议了～</li>
  <li>如果要急着陪女票的话，推荐直接看最后的 <em>7. Spark 2.0, 必须知道的几个点</em></li>
</ul>

<p>上一篇文章： 
<a href="http://litaotao.github.io/spark-2.0-faster-easier-smarter">『 Spark 』12. Spark 2.0  | 10 个特性介绍</a></p>

<h2 id="1-api-stability">1. API Stability</h2>

<p>spark 保证 2.x 中非实验性的 api 的稳定性，2.x 中大部分 api 都与 1.x 中保持一致，但是删除了一些 api，更新了一些 api，并且有部分 api 打算在后续升级中移除，具体见下面，完整的列表参考：<a href="https://issues.apache.org/jira/browse/SPARK-11806">Spark 2.0 deprecations and removals</a></p>

<h3 id="11-removals-api">1.1 Removals API</h3>

<ul>
  <li>Bagel</li>
  <li><em>不支持 Hadoop 2.1 及之前老版本</em></li>
  <li>The ability to configure closure serializer [闭包序列化？]</li>
  <li>HTTPBroadcast</li>
  <li>TTL-based metadata cleaning</li>
  <li>删除 org.apache.spark.Logging，推荐直接食用 slf4j 包</li>
  <li>SparkContext.metricsSystem</li>
  <li>Block-oriented integration with Tachyon (subsumed by file system integration)</li>
  <li>删掉在 1.x 中标注为 deprecated 的 api</li>
  <li>Methods on Python DataFrame that returned RDDs (map, flatMap, mapPartitions, etc). They are still available in dataframe.rdd field, e.g. dataframe.rdd.map.</li>
  <li>Less frequently used streaming connectors, including Twitter, Akka, MQTT, ZeroMQ [不知道为啥要删掉这些 api，估计是因为 structure streaming 改动比较大，难以实现这些 connector 吧]</li>
  <li>Hash-based shuffle manager</li>
  <li>History serving functionality from standalone Master</li>
  <li>For Java and Scala, DataFrame no longer exists as a class. As a result, data sources would need to be updated.</li>
  <li>Spark EC2 script 被迁移到另外一个 repo，本身与 spark 框架无关</li>
</ul>

<h3 id="12-behavior-changes-api">1.2 Behavior Changes API</h3>

<ul>
  <li><em>默认使用 scala 2.11 编译，之前默认是 2.10</em></li>
  <li>sparksql 中，float 数据类型被解析成 decimal 类型，之前是被解析成 double 类型</li>
  <li>Kryo 升级到 3.0</li>
  <li>java 中，RDD.flatMap 和 RDD.mapPartitions 中的函数不需要返回所有数据，只需要能返回一个迭代器即可</li>
  <li>Java RDD’s countByKey and countAprroxDistinctByKey now returns a map from K to java.lang.Long, rather than to java.lang.Object.</li>
  <li>When writing Parquet files, the summary files are not written by default. To re-enable it, users must set “parquet.enable.summary-metadata” to true.</li>
  <li>The DataFrame-based API (spark.ml) now depends upon local linear algebra in spark.ml.linalg, rather than in spark.mllib.linalg.</li>
</ul>

<h3 id="13-deprecations">1.3 Deprecations</h3>

<ul>
  <li><em>Mesos 中的 Fine-grained 模式</em></li>
  <li><em>不支持 Java 7</em></li>
  <li><em>不支持 Support for Python 2.6</em></li>
</ul>

<h2 id="2-core-and-spark-sql">2. Core and Spark SQL</h2>

<h3 id="21-programming-apis">2.1 Programming APIs</h3>

<ul>
  <li><em>统一 DataFrame 和 Dataset，在 Scala 和 Java 中, DataFrame 和 Dataset 完成合并；在 Python 和 R 中, DataFrame 和 Dataset 没有合并；</em></li>
  <li>SparkSession: 新的spark 程序入口，SQLContext 和 HiveContext 仍然可用；</li>
  <li>新的 streaming 配置；</li>
  <li>新的 accumulator API；</li>
  <li>A new, improved Aggregator API for typed aggregation in Datasets</li>
</ul>

<h3 id="22-sql">2.2 SQL</h3>

<p><em>Spark 2.0 完全支持 SQL2003 标准.</em></p>

<ul>
  <li>更原生带 sql 解析器；</li>
  <li>Native DDL command implementations</li>
  <li>支持子查询，包括：
    <ul>
      <li>Uncorrelated Scalar Subqueries</li>
      <li>Correlated Scalar Subqueries</li>
      <li>NOT IN predicate Subqueries (in WHERE/HAVING clauses)</li>
      <li>IN predicate subqueries (in WHERE/HAVING clauses)</li>
      <li>(NOT) EXISTS predicate subqueries (in WHERE/HAVING clauses)</li>
    </ul>
  </li>
  <li>View canonicalization support</li>
  <li>In addition, when building without Hive support, Spark SQL should have almost all the functionality as when building with Hive support, with the exception of Hive connectivity, Hive UDFs, and script transforms.</li>
</ul>

<h3 id="23-new-features">2.3 New Features</h3>

<ul>
  <li><em>原生支持 CSV 数据源, 基于 Databricks 的 spark-csv 包；</em></li>
  <li><em>cache 和运行时的堆外内存管理</em></li>
  <li>Hive style bucketing support</li>
  <li>Approximate summary statistics using sketches, including approximate quantile, Bloom filter, and count-min sketch.</li>
</ul>

<h3 id="24-performance-and-runtime">2.4 Performance and Runtime</h3>

<ul>
  <li><em>2～10 倍的性能提升，得益于 whole stage code generation 方案；</em></li>
  <li>改善 Parquet 文件的扫描性能</li>
  <li>改善 ORC performance</li>
  <li>改善 Catalyst query 优化器</li>
  <li>改善 window function</li>
  <li>Automatic file coalescing for native data sources</li>
</ul>

<h2 id="3-mllib">3. MLlib</h2>

<p>在 2.x 中，DataFrame-based API 会是主要开发，维护的新的 mllib api。</p>

<ul>
  <li>ML persistence: The DataFrames-based API provides near-complete support for saving and loading ML models and Pipelines in Scala, Java, Python, and R. See <a href="https://databricks.com/blog/2016/05/31/apache-spark-2-0-preview-machine-learning-model-persistence.html">this blog</a> post and the following JIRAs for details: SPARK-6725, SPARK-11939, SPARK-14311.</li>
  <li>MLlib in R: SparkR now offers MLlib APIs for generalized linear models, naive Bayes, k-means clustering, and survival regression.</li>
  <li>Python: PySpark now offers many more MLlib algorithms, including LDA, Gaussian Mixture Model, Generalized Linear Regression, and more.</li>
  <li>Algorithms added to DataFrames-based API: Bisecting K-Means clustering, Gaussian Mixture Model, MaxAbsScaler feature transformer.</li>
</ul>

<h2 id="4-sparkr">4. SparkR</h2>

<p>最大的改善是 2.x 中，sparkr 支持3个 udf: dapply, gapply, and lapply.</p>

<ul>
  <li>Improved algorithm coverage for machine learning in R, including naive Bayes, k-means clustering, and survival regression.</li>
  <li>Generalized linear models support more families and link functions.</li>
  <li>Save and load for all ML models.</li>
  <li>More DataFrame functionality: Window functions API, reader, writer support for JDBC, CSV, SparkSession</li>
</ul>

<h2 id="5-streaming">5. Streaming</h2>

<p><em>新的 streaming 框架 Structured Streaming, 其中 DStream API 大多数都是处于试验阶段，并且只支持 Kafka 0.10 的connector.</em></p>

<h2 id="6-dependency-packaging-and-operations">6. Dependency, Packaging, and Operations</h2>

<ul>
  <li>Spark 2.0 no longer requires a fat assembly jar for production deployment.</li>
  <li>Akka dependency has been removed, and as a result, user applications can program against any versions of Akka.</li>
  <li>Support launching multiple Mesos executors in coarse grained Mesos mode.</li>
  <li>Kryo version is bumped to 3.0.</li>
  <li>The default build is now using Scala 2.11 rather than Scala 2.10.</li>
</ul>

<h2 id="7-spark-20-必须知道的几个点">7. Spark 2.0, 必须知道的几个点</h2>

<ul>
  <li>不支持 Hadoop 2.1 及之前老版本</li>
  <li>默认使用 scala 2.11 编译，之前默认是 2.10</li>
  <li>Mesos 中的 Fine-grained 模式 [Deprecations]</li>
  <li>不支持 Java 7 [Deprecations]</li>
  <li>不支持 Support for Python 2.6 [Deprecations]</li>
  <li>Spark 2.0 完全支持 SQL2003 标准</li>
  <li>原生支持 CSV 数据源, 基于 Databricks 的 spark-csv 包；</li>
  <li>SparkSession: 新的spark 程序入口，SQLContext 和 HiveContext 仍然可用；</li>
  <li>sql中 2～10 倍的性能提升，得益于 whole stage code generation 方案；</li>
  <li>统一 DataFrame 和 Dataset，在 Scala 和 Java 中, DataFrame 和 Dataset 完成合并；在 Python 和 R 中, DataFrame 和 Dataset 没有合并；</li>
  <li>cache 和运行时的堆外内存管理</li>
  <li>新的 streaming 框架 Structured Streaming, 其中 DStream API 大多数都是处于试验阶段，并且只支持 Kafka 0.10 的connector.</li>
</ul>

<h2 id="14-打开微信扫一扫点一点棒棒的_">14. 打开微信，扫一扫，点一点，棒棒的，^_^</h2>

<p><img src="../images/wechat_pay_6-6.png" alt="wechat_pay_6-6.png" /></p>

<h2 id="参考文章">参考文章</h2>

<ul>
  <li><a href="http://spark.apache.org/releases/spark-release-2-0-0.html">Spark Release 2.0.0</a></li>
  <li><a href="https://issues.apache.org/jira/browse/SPARK-11806">Spark 2.0 deprecations and removals</a></li>
  <li><a href="https://spark-summit.org/2016/events/apache-spark-mllib-20-preview-data-science-and-production/">APACHE SPARK MLLIB 2.0 PREVIEW: DATA SCIENCE AND PRODUCTION</a></li>
</ul>

<h2 id="本系列文章链接">本系列文章链接</h2>

<ul>
  <li><a href="http://litaotao.github.io/introduction-to-spark?s=inner">『 Spark 』1. spark 简介 </a></li>
  <li><a href="http://litaotao.github.io/spark-questions-concepts?s=inner">『 Spark 』2. spark 基本概念解析 </a></li>
  <li><a href="http://litaotao.github.io/spark-programming-model?s=inner">『 Spark 』3. spark 编程模式 </a></li>
  <li><a href="http://litaotao.github.io/spark-what-is-rdd?s=inner">『 Spark 』4. spark 之 RDD </a></li>
  <li><a href="http://litaotao.github.io/spark-resouces-blogs-paper?s=inner">『 Spark 』5. 这些年，你不能错过的 spark 学习资源 </a></li>
  <li><a href="http://litaotao.github.io/deep-into-spark-exection-model?s=inner">『 Spark 』6. 深入研究 spark 运行原理之 job, stage, task</a></li>
  <li><a href="http://litaotao.github.io/spark-dataframe-introduction?s=inner">『 Spark 』7. 使用 Spark DataFrame 进行大数据分析</a></li>
  <li><a href="http://litaotao.github.io/spark-in-finance-and-investing?s=inner">『 Spark 』8. 实战案例 ｜ Spark 在金融领域的应用 ｜ 日内走势预测</a></li>
  <li><a href="http://litaotao.github.io/ipython-notebook-spark?s=inner">『 Spark 』9. 搭建 IPython + Notebook + Spark 开发环境</a></li>
  <li><a href="http://litaotao.github.io/boost-spark-application-performance?s=inner">『 Spark 』10. spark 应用程序性能优化｜12 个优化方法</a></li>
  <li><a href="http://litaotao.github.io/spark-mlib-machine-learning?s=inner">『 Spark 』11. spark 机器学习</a></li>
  <li><a href="http://litaotao.github.io/spark-2.0-faster-easier-smarter?s=inner">『 Spark 』12. Spark 2.0 特性介绍</a></li>
  <li><a href="http://litaotao.github.io/spark-2.0-release-notes-zh?s=inner">『 Spark 』13. Spark 2.0 Release Notes 中文版 </a></li>
  <li><a href="http://litaotao.github.io/spark-sql-parquet-optimize?s=inner">『 Spark 』14. 一次 Spark SQL 性能优化之旅</a></li>
</ul>


    <!-- share icon -->
    <!-- <div class="ds-share" data-thread-key="/spark-2.0-release-notes-zh" data-title="『 Spark 』13. Spark 2.0 Release Notes 中文版"
         data-content="content"
         data-url="http://litaotao.github.io//spark-2.0-release-notes-zh">
        <div class="ds-share-aside-left">
          <div class="ds-share-aside-inner">
          </div>
          <div class="ds-share-aside-toggle">分享</div>
        </div>
    </div>
 -->
    <!-- 百度分享按钮 -->

<script>window._bd_share_config={"common":{"bdSnsKey":{},"bdText":"","bdMini":"1","bdMiniList":false,"bdPic":"","bdStyle":"0","bdSize":"16"},"slide":{"type":"slide","bdImg":"7","bdPos":"left","bdTop":"118"},"image":{"viewList":["weixin","qzone","tsina","tqq","renren","sqq","evernotecn","youdao"],"viewText":"分享到：","viewSize":"16"},"selectShare":{"bdContainerClass":null,"bdSelectMiniList":["weixin","qzone","tsina","tqq","renren","sqq","evernotecn","youdao"]}};with(document)0[(getElementsByTagName('head')[0]||body).appendChild(createElement('script')).src='http://bdimg.share.baidu.com/static/api/js/share.js?v=89860593.js?cdnversion='+~(-new Date()/36e5)];</script>


<!--     <div id="disqus_container">
      <div style="margin-bottom:20px">
      多说评论框 start
        <div class="ds-thread" data-thread-key=/spark-2.0-release-notes-zh data-title=『 Spark 』13. Spark 2.0 Release Notes 中文版 
             data-url=http://localhost:4000+/spark-2.0-release-notes-zh></div>
      多说评论框 end
      多说公共JS代码 start (一个网页只需插入一次)
      <script type="text/javascript">
      var duoshuoQuery = {short_name:"litaotao"};
        (function() {
          var ds = document.createElement('script');
          ds.type = 'text/javascript';ds.async = true;
          // ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
          ds.src = '../js/embed.js'
          ds.charset = 'UTF-8';
          (document.getElementsByTagName('head')[0]
           || document.getElementsByTagName('body')[0]).appendChild(ds);
        })();
        </script>
      多说公共JS代码 end
      </div>
    </div> -->

        <div id="disqus_thread"></div>
            <script>

            /**
            *  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.
            *  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables*/
            /*
            var disqus_config = function () {
            this.page.url = PAGE_URL;  // Replace PAGE_URL with your page's canonical URL variable
            this.page.identifier = PAGE_IDENTIFIER; // Replace PAGE_IDENTIFIER with your page's unique identifier variable
            };
            */
            (function() { // DON'T EDIT BELOW THIS LINE
            var d = document, s = d.createElement('script');
            s.src = 'https://litaotao-github-io.disqus.com/embed.js';
            s.setAttribute('data-timestamp', +new Date());
            (d.head || d.body).appendChild(s);
            })();
            </script>
            <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>    

  </div>
  
  <div id="menuIndex" class="sidenav">
    <div class="myinfo">
        <center>
          <div id="avatarHolder" class="avatar circle" style="width: 0px; height: 0px; box-shadow: none; margin-bottom: 20px;">
          </div>
          <a href="/index.html" title="Homepage"><i class="icon-home icon-large"></i> Home</a>
          <a href="http://www.linkedin.com/in/taotaoli"><i class="icon-linkedin-sign icon-large"></i> Linkedin</a>
          <a href="https://github.com/zxy"><i class="icon-github icon-large"></i> Code</a>
          <a href="mailto:1757943205@qq.com"><i class="icon-envelope icon-large"></i> Mail</a>
          <button id="present_button" onclick="present_mode()" style="width: 100%; margin-top: 10px; display: none"><i class="icon-align-justify icon-large"></i> Present Mode</button>
        </center>
    </div>
    <div id="menu"></div>
  </div>
</div>

<script src="/js/post.js" type="text/javascript"></script>
<script type="text/javascript">
    //博文页面也做一下刷新操作，避免有时候切换横竖屏时格式不对的问题  
    // $( window ).resize(function() { 
    //     location.reload(); 
    // });
</script>


  <script type="text/javascript">
    var cnzz_protocol = (("https:" == document.location.protocol) ? " https://" : " http://");
    document.write(unescape("%3Cspan id='cnzz_stat_icon_1258855744'%3E%3C/span%3E%3Cscript src='" + cnzz_protocol + "s11.cnzz.com/z_stat.php%3Fid%3D1258855744' type='text/javascript'%3E%3C/script%3E"));
  </script>

</body>
</html>
